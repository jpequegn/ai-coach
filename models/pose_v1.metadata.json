{
  "model_name": "YOLOv8n-pose",
  "version": "1.0",
  "framework": "Ultralytics YOLOv8",
  "format": "ONNX",
  "opset_version": 11,
  "task": "pose_estimation",
  "architecture": "anchor-free, single-stage, heatmap-free",
  "date_created": "2025-10-02",
  "file_size_mb": 12.89,
  "license": "AGPL-3.0",
  "source_url": "https://github.com/ultralytics/ultralytics",
  "description": "YOLOv8 nano variant for human pose estimation with 17 COCO keypoints. Optimized for real-time inference on CPU/GPU with multi-person detection capability.",

  "input": {
    "name": "images",
    "shape": [1, 3, 640, 640],
    "type": "float32",
    "format": "NCHW",
    "color_space": "RGB",
    "normalization": {
      "method": "scale",
      "range": [0.0, 1.0],
      "formula": "pixel_value / 255.0"
    },
    "preprocessing": [
      "Resize image to 640x640 with letterbox padding (maintain aspect ratio)",
      "Convert BGR to RGB (if using OpenCV)",
      "Normalize pixel values to [0.0, 1.0]",
      "Transpose to NCHW format (channels-first)",
      "Add batch dimension"
    ]
  },

  "output": {
    "name": "output0",
    "shape": [1, 56, 8400],
    "type": "float32",
    "format": {
      "dimensions": ["batch", "attributes", "anchors"],
      "attributes_count": 56,
      "anchors_count": 8400,
      "attribute_layout": [
        {"name": "x", "index": 0, "description": "Bounding box center X (normalized 0-1)"},
        {"name": "y", "index": 1, "description": "Bounding box center Y (normalized 0-1)"},
        {"name": "width", "index": 2, "description": "Bounding box width (normalized 0-1)"},
        {"name": "height", "index": 3, "description": "Bounding box height (normalized 0-1)"},
        {"name": "confidence", "index": 4, "description": "Detection confidence score"},
        {"name": "keypoints", "indices": [5, 55], "description": "17 keypoints Ã— 3 values (x, y, confidence)"}
      ]
    },
    "postprocessing": [
      "Transpose output to [batch, anchors, attributes] for easier processing",
      "Filter detections by confidence threshold (default: 0.5)",
      "Apply Non-Maximum Suppression (NMS) with IoU threshold (default: 0.45)",
      "Extract keypoints from remaining detections",
      "Denormalize coordinates to original image dimensions"
    ]
  },

  "keypoints": {
    "format": "COCO",
    "count": 17,
    "layout": [
      {"id": 0, "name": "nose", "type": "facial"},
      {"id": 1, "name": "left_eye", "type": "facial"},
      {"id": 2, "name": "right_eye", "type": "facial"},
      {"id": 3, "name": "left_ear", "type": "facial"},
      {"id": 4, "name": "right_ear", "type": "facial"},
      {"id": 5, "name": "left_shoulder", "type": "upper_body"},
      {"id": 6, "name": "right_shoulder", "type": "upper_body"},
      {"id": 7, "name": "left_elbow", "type": "upper_body"},
      {"id": 8, "name": "right_elbow", "type": "upper_body"},
      {"id": 9, "name": "left_wrist", "type": "upper_body"},
      {"id": 10, "name": "right_wrist", "type": "upper_body"},
      {"id": 11, "name": "left_hip", "type": "lower_body"},
      {"id": 12, "name": "right_hip", "type": "lower_body"},
      {"id": 13, "name": "left_knee", "type": "lower_body"},
      {"id": 14, "name": "right_knee", "type": "lower_body"},
      {"id": 15, "name": "left_ankle", "type": "lower_body"},
      {"id": 16, "name": "right_ankle", "type": "lower_body"}
    ],
    "skeleton_connections": [
      [0, 1], [0, 2], [1, 3], [2, 4],
      [5, 6], [5, 7], [7, 9], [6, 8], [8, 10],
      [5, 11], [6, 12], [11, 12],
      [11, 13], [13, 15], [12, 14], [14, 16]
    ]
  },

  "performance": {
    "inference_speed": {
      "target_ms": 100,
      "cpu_expected_ms": 50,
      "gpu_expected_ms": 10,
      "notes": "Benchmarks on Apple M3, Intel i7, or NVIDIA RTX 30-series"
    },
    "accuracy": {
      "dataset": "COCO val2017",
      "map50": "High (exact metrics TBD after testing)",
      "confidence_threshold_recommended": 0.5,
      "nms_iou_threshold_recommended": 0.45
    },
    "resource_usage": {
      "memory_mb": 200,
      "vram_mb": 300,
      "notes": "Approximate values during inference"
    }
  },

  "capabilities": {
    "multi_person_detection": true,
    "real_time_inference": true,
    "gpu_acceleration": true,
    "batch_processing": true,
    "video_streaming": true
  },

  "limitations": {
    "single_person_optimized": false,
    "requires_good_lighting": true,
    "occlusion_handling": "moderate",
    "min_person_height_pixels": 50,
    "max_persons_per_frame": "unlimited (but performance degrades with >10)"
  },

  "inference_parameters": {
    "confidence_threshold": {
      "default": 0.5,
      "range": [0.1, 0.95],
      "description": "Minimum confidence score to consider a detection valid"
    },
    "nms_iou_threshold": {
      "default": 0.45,
      "range": [0.3, 0.7],
      "description": "IoU threshold for Non-Maximum Suppression to filter overlapping detections"
    },
    "keypoint_confidence_threshold": {
      "default": 0.5,
      "range": [0.1, 0.95],
      "description": "Minimum confidence score for individual keypoint visibility"
    }
  },

  "training_info": {
    "dataset": "COCO Keypoints 2017",
    "pretrained": true,
    "image_count": 149813,
    "keypoint_annotations": "Over 200K person instances",
    "epochs": "300 (from Ultralytics pretrained)",
    "input_size": "640x640",
    "augmentations": [
      "Mosaic",
      "MixUp",
      "Random HSV",
      "Random Flip",
      "Random Scale",
      "Random Translate"
    ]
  },

  "runtime_support": {
    "onnxruntime": {
      "supported": true,
      "version_min": "1.10.0",
      "rust_crate": "ort",
      "execution_providers": ["CPU", "CUDA", "CoreML", "TensorRT"]
    },
    "tract": {
      "supported": true,
      "notes": "Alternative Rust ONNX runtime, less tested with YOLOv8-pose"
    }
  },

  "references": {
    "documentation": "https://docs.ultralytics.com/tasks/pose/",
    "github": "https://github.com/ultralytics/ultralytics",
    "paper": "https://arxiv.org/abs/2305.09972",
    "coco_keypoints": "https://cocodataset.org/#keypoints-2020",
    "export_guide": "https://docs.ultralytics.com/modes/export/"
  },

  "changelog": [
    {
      "version": "1.0",
      "date": "2025-10-02",
      "changes": [
        "Initial YOLOv8n-pose ONNX export",
        "Opset 11 with onnxslim optimization",
        "Model size: 12.89 MB",
        "Created comprehensive metadata"
      ]
    }
  ],

  "next_steps": [
    "Integrate ort crate into ai-coach-api",
    "Create PoseEstimationService in Rust",
    "Implement preprocessing pipeline",
    "Implement postprocessing (NMS, keypoint extraction)",
    "Add temporal smoothing for video",
    "Create performance benchmarks",
    "Test on various video qualities"
  ]
}
